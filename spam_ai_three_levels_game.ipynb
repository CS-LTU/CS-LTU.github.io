{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2d4c65",
   "metadata": {},
   "source": [
    "# Spam Detection AI Game: Three Levels of AI\n",
    "\n",
    "This notebook shows three different AI approaches to detect spam emails and plugs them into a simple \"Inbox Duel\" game where a human player competes with the AI:\n",
    "\n",
    "1. Classical machine learning with TF‑IDF + Linear SVM\n",
    "2. Transformer-based model (DistilBERT embeddings + Logistic Regression)\n",
    "3. Cloud LLM spam oracle (API-based, skeleton code)\n",
    "\n",
    "The dataset is deliberately tiny and hard-coded so you can run this quickly and extend it in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you run this in a fresh environment (e.g. Google Colab), uncomment this cell.\n",
    "# !pip install pandas scikit-learn transformers torch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7e3795",
   "metadata": {},
   "source": [
    "## 1. Mini email dataset and train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import textwrap\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Built-in mini dataset: (label, text)\n",
    "data = [\n",
    "    (\"spam\", \"Congratulations! You have won a $1000 gift card. Click here to claim now!\"),\n",
    "    (\"spam\", \"WIN a brand new iPhone. Limited time offer, act now!\"),\n",
    "    (\"spam\", \"You have been selected for a lottery prize, reply with your bank details.\"),\n",
    "    (\"spam\", \"Cheap meds online!!! Buy now with 90% discount.\"),\n",
    "    (\"spam\", \"This is not a scam. Send your password to verify your account.\"),\n",
    "    (\"ham\",  \"Hi John, can we move our meeting to tomorrow morning?\"),\n",
    "    (\"ham\",  \"Reminder: your dentist appointment is on Friday at 10am.\"),\n",
    "    (\"ham\",  \"Thanks for sending over the report, I'll review it tonight.\"),\n",
    "    (\"ham\",  \"Mum’s birthday is next week – shall we book a restaurant?\"),\n",
    "    (\"ham\",  \"Here are the notes from today’s lecture, let me know if you have questions.\"),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"label\", \"text\"])\n",
    "df[\"label_num\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "X = df[\"text\"].tolist()\n",
    "y = df[\"label_num\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train), \" Test size:\", len(X_test))\n",
    "for text, label in zip(X_train[:3], y_train[:3]):\n",
    "    print(f\"[{'spam' if label else 'ham'}] {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555773c2",
   "metadata": {},
   "source": [
    "## 2. Level 1: Classical model (TF‑IDF + Linear SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import math\n",
    "\n",
    "# TF‑IDF + Linear SVM with unigrams + bigrams\n",
    "svm_model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        max_df=0.9,\n",
    "        ngram_range=(1, 2)\n",
    "    )),\n",
    "    (\"clf\", LinearSVC())\n",
    "])\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"SVM performance on test set:\")\n",
    "svm_preds = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, svm_preds, target_names=[\"ham\", \"spam\"]))\n",
    "\n",
    "def svm_predict_label(text: str) -> int:\n",
    "    \"\"\"Return 1 for spam, 0 for ham.\"\"\"\n",
    "    return int(svm_model.predict([text])[0])\n",
    "\n",
    "def svm_confidence(text: str) -> float:\n",
    "    \"\"\"Pseudo-confidence based on distance from decision boundary.\"\"\"\n",
    "    dist = svm_model.decision_function([text])[0]\n",
    "    return 1.0 / (1.0 + math.exp(-dist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebebb4b",
   "metadata": {},
   "source": [
    "## 3. Level 2: Transformer-based model (DistilBERT embeddings + Logistic Regression)\n",
    "\n",
    "This section downloads a pre-trained DistilBERT model, uses it to turn emails into vector embeddings, then trains a simple Logistic Regression classifier on top.\n",
    "\n",
    "Note: the first run will download model weights and may take a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e98e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
    "\n",
    "def embed_texts(texts, batch_size: int = 8):\n",
    "    \"\"\"Return a NumPy array of vector embeddings for a list of texts.\"\"\"\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        tokens = tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**tokens)\n",
    "        # Mean pooling over sequence length\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        all_embeddings.append(embeddings.cpu())\n",
    "    return torch.cat(all_embeddings, dim=0).numpy()\n",
    "\n",
    "X_train_emb = embed_texts(X_train)\n",
    "X_test_emb = embed_texts(X_test)\n",
    "\n",
    "bert_clf = LogisticRegression(max_iter=1000)\n",
    "bert_clf.fit(X_train_emb, y_train)\n",
    "\n",
    "print(\"DistilBERT + LogisticRegression performance on test set:\")\n",
    "bert_preds = bert_clf.predict(X_test_emb)\n",
    "print(classification_report(y_test, bert_preds, target_names=[\"ham\", \"spam\"]))\n",
    "\n",
    "def bert_predict_label(text: str) -> int:\n",
    "    emb = embed_texts([text])\n",
    "    return int(bert_clf.predict(emb)[0])\n",
    "\n",
    "def bert_confidence(text: str) -> float:\n",
    "    emb = embed_texts([text])\n",
    "    prob = bert_clf.predict_proba(emb)[0][1]  # probability of spam\n",
    "    return float(prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14664ee",
   "metadata": {},
   "source": [
    "## 4. Level 3: Cloud LLM spam oracle (skeleton)\n",
    "\n",
    "In a production system, you can also ask a cloud-hosted LLM to classify each email as spam or ham.\n",
    "\n",
    "Below is a **skeleton** for such an integration. You need to plug in your own API call to your chosen provider (e.g. OpenAI, Anthropic, etc.) and parse the response to return `1` for spam and `0` for ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_predict_label(text: str) -> int:\n",
    "    \"\"\"Placeholder: call your LLM provider and return 1 for spam, 0 for ham.\n",
    "\n",
    "    Example logic (pseudocode):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"your-llm-model\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a spam filter.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Is this email spam or ham? Only answer 'spam' or 'ham'.\\n\\n{text}\"},\n",
    "            ],\n",
    "        )\n",
    "        label_str = response.choices[0].message.content.strip().lower()\n",
    "        return 1 if label_str == \"spam\" else 0\n",
    "\n",
    "    For safety and to keep this notebook self-contained, this function just raises\n",
    "    NotImplementedError. Implement it yourself if you have an API key and provider.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Plug in your cloud LLM spam classifier here.\")\n",
    "\n",
    "def llm_confidence(text: str) -> float:\n",
    "    \"\"\"Placeholder confidence score for LLM-based classification.\n",
    "\n",
    "    You could, for example, instruct the model to output a probability or confidence\n",
    "    alongside the label and parse it here.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Return a confidence score from the LLM response.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05314d",
   "metadata": {},
   "source": [
    "## 5. Shared game engine: Inbox Duel (human vs AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f067300",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AIOpponent:\n",
    "    name: str\n",
    "    predict_label: Callable[[str], int]\n",
    "    confidence: Callable[[str], float]\n",
    "\n",
    "def play_inbox_duel(ai: AIOpponent, test_texts=None, test_labels=None):\n",
    "    \"\"\"Simple terminal game: human vs AI spam detector.\n",
    "\n",
    "    The player and the AI both try to classify the same sequence of emails.\n",
    "    +1 point for each correct answer.\n",
    "    \"\"\"\n",
    "    if test_texts is None or test_labels is None:\n",
    "        texts = X_test\n",
    "        labels = y_test\n",
    "    else:\n",
    "        texts = test_texts\n",
    "        labels = test_labels\n",
    "\n",
    "    pairs = list(zip(texts, labels))\n",
    "    random.shuffle(pairs)\n",
    "\n",
    "    player_score = 0\n",
    "    ai_score = 0\n",
    "    WRAP_WIDTH = 80\n",
    "\n",
    "    print(f\"\\n=== Inbox Duel: You vs {ai.name} ===\")\n",
    "    print(\"Type 's' for spam, 'h' for ham, 'q' to quit.\\n\")\n",
    "\n",
    "    def show_email(email_text):\n",
    "        print(\"\\n\" + \"-\" * WRAP_WIDTH)\n",
    "        print(\"New email received:\")\n",
    "        print(\"-\" * WRAP_WIDTH)\n",
    "        for line in textwrap.wrap(email_text, width=WRAP_WIDTH):\n",
    "            print(line)\n",
    "        print(\"-\" * WRAP_WIDTH)\n",
    "\n",
    "    def ask_player():\n",
    "        while True:\n",
    "            ans = input(\"Is this spam or not? (s = spam, h = ham, q = quit): \").strip().lower()\n",
    "            if ans in [\"s\", \"h\", \"q\"]:\n",
    "                return ans\n",
    "            print(\"Please type 's', 'h', or 'q'.\")\n",
    "\n",
    "    for email_text, true_label in pairs:\n",
    "        show_email(email_text)\n",
    "        player_choice = ask_player()\n",
    "        if player_choice == \"q\":\n",
    "            break\n",
    "\n",
    "        player_label = 1 if player_choice == \"s\" else 0\n",
    "        ai_label = ai.predict_label(email_text)\n",
    "        ai_conf = ai.confidence(email_text)\n",
    "\n",
    "        true_str = \"spam\" if true_label == 1 else \"ham\"\n",
    "        player_str = \"spam\" if player_label == 1 else \"ham\"\n",
    "        ai_str = \"spam\" if ai_label == 1 else \"ham\"\n",
    "        \n",
    "        print(f\"\\nGround truth: {true_str.upper()}\")\n",
    "        print(f\"Your answer:  {player_str.upper()}\")\n",
    "        print(f\"{ai.name} answer: {ai_str.upper()} (confidence = {ai_conf:.2f})\")\n",
    "\n",
    "        if player_label == true_label:\n",
    "            player_score += 1\n",
    "            print(\"You: +1 point\")\n",
    "        if ai_label == true_label:\n",
    "            ai_score += 1\n",
    "            print(f\"{ai.name}: +1 point\")\n",
    "\n",
    "        print(f\"Scores -> You: {player_score} | {ai.name}: {ai_score}\\n\")\n",
    "\n",
    "    print(\"\\nGame over!\")\n",
    "    print(f\"Final scores -> You: {player_score} | {ai.name}: {ai_score}\")\n",
    "    if player_score > ai_score:\n",
    "        print(\"You beat the AI!\")\n",
    "    elif player_score < ai_score:\n",
    "        print(f\"{ai.name} wins this time.\")\n",
    "    else:\n",
    "        print(\"It's a draw.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea309aeb",
   "metadata": {},
   "source": [
    "## 6. Choose your AI opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical SVM opponent\n",
    "svm_ai = AIOpponent(\n",
    "    name=\"SVM spam detector\",\n",
    "    predict_label=svm_predict_label,\n",
    "    confidence=svm_confidence,\n",
    ")\n",
    "\n",
    "# Transformer-based opponent\n",
    "bert_ai = AIOpponent(\n",
    "    name=\"DistilBERT spam detector\",\n",
    "    predict_label=bert_predict_label,\n",
    "    confidence=bert_confidence,\n",
    ")\n",
    "\n",
    "# Cloud LLM opponent (once you implement llm_predict_label / llm_confidence)\n",
    "llm_ai = AIOpponent(\n",
    "    name=\"Cloud LLM spam oracle\",\n",
    "    predict_label=llm_predict_label,\n",
    "    confidence=llm_confidence,\n",
    ")\n",
    "\n",
    "print(\"Defined opponents: svm_ai, bert_ai, llm_ai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: play against the classical SVM model\n",
    "# Uncomment one line at a time to try different opponents.\n",
    "\n",
    "# play_inbox_duel(svm_ai)\n",
    "# play_inbox_duel(bert_ai)\n",
    "# play_inbox_duel(llm_ai)  # once LLM functions are implemented\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
